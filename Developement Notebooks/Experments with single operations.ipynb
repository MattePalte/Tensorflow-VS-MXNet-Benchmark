{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.identity(3)\n",
    "B = np.reshape(np.arange(100), (10,10))\n",
    "bias = np.reshape(np.zeros(100), (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[16:03:12] src/operator/nn/convolution.cc:152: Check failed: dshp.ndim() == 4U (2 vs. 4) : Input data should be 4D in batch-num_filter-y-x\nStack trace:\n  [bt] (0) 1   libmxnet.so                         0x000000011b148929 mxnet::op::NDArrayOpProp::~NDArrayOpProp() + 4473\n  [bt] (1) 2   libmxnet.so                         0x000000011b47605b void mxnet::op::ConcatCSRImpl<mshadow::cpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 141355\n  [bt] (2) 3   libmxnet.so                         0x000000011c6c5f23 mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*) + 1603\n  [bt] (3) 4   libmxnet.so                         0x000000011c6c483c mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 716\n  [bt] (4) 5   libmxnet.so                         0x000000011c60a48e SetNDInputsOutputs(nnvm::Op const*, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> >*, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> >*, int, void* const*, int*, int, int, void***) + 1582\n  [bt] (5) 6   libmxnet.so                         0x000000011c60b1d0 MXImperativeInvokeEx + 176\n  [bt] (6) 7   _ctypes.cpython-37m-darwin.so       0x000000010a70d0d7 ffi_call_unix64 + 79\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0779af3461c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mB_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbias_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mB_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mConvolution\u001b[0;34m(data, weight, bias, kernel, stride, dilate, pad, num_filter, num_group, workspace, no_bias, cudnn_tune, cudnn_off, layout, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [16:03:12] src/operator/nn/convolution.cc:152: Check failed: dshp.ndim() == 4U (2 vs. 4) : Input data should be 4D in batch-num_filter-y-x\nStack trace:\n  [bt] (0) 1   libmxnet.so                         0x000000011b148929 mxnet::op::NDArrayOpProp::~NDArrayOpProp() + 4473\n  [bt] (1) 2   libmxnet.so                         0x000000011b47605b void mxnet::op::ConcatCSRImpl<mshadow::cpu>(nnvm::NodeAttrs const&, mxnet::OpContext const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&, std::__1::vector<mxnet::OpReqType, std::__1::allocator<mxnet::OpReqType> > const&, std::__1::vector<mxnet::NDArray, std::__1::allocator<mxnet::NDArray> > const&) + 141355\n  [bt] (2) 3   libmxnet.so                         0x000000011c6c5f23 mxnet::imperative::SetShapeType(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, mxnet::DispatchMode*) + 1603\n  [bt] (3) 4   libmxnet.so                         0x000000011c6c483c mxnet::Imperative::Invoke(mxnet::Context const&, nnvm::NodeAttrs const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&) + 716\n  [bt] (4) 5   libmxnet.so                         0x000000011c60a48e SetNDInputsOutputs(nnvm::Op const*, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> >*, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> >*, int, void* const*, int*, int, int, void***) + 1582\n  [bt] (5) 6   libmxnet.so                         0x000000011c60b1d0 MXImperativeInvokeEx + 176\n  [bt] (6) 7   _ctypes.cpython-37m-darwin.so       0x000000010a70d0d7 ffi_call_unix64 + 79\n\n"
     ]
    }
   ],
   "source": [
    "A_mx = mx.nd.array(A)\n",
    "B_mx = mx.nd.array(B)\n",
    "bias_mx = mx.nd.array(bias)\n",
    "R = mx.ndarray.op.Convolution(data=B_mx, weight=A_mx, bias=bias_mx, kernel=(3,3), num_filter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function Convolution:\n",
      "\n",
      "Convolution(data=None, weight=None, bias=None, kernel=_Null, stride=_Null, dilate=_Null, pad=_Null, num_filter=_Null, num_group=_Null, workspace=_Null, no_bias=_Null, cudnn_tune=_Null, cudnn_off=_Null, layout=_Null, out=None, name=None, **kwargs)\n",
      "    Compute *N*-D convolution on *(N+2)*-D input.\n",
      "    \n",
      "    In the 2-D convolution, given input data with shape *(batch_size,\n",
      "    channel, height, width)*, the output is computed by\n",
      "    \n",
      "    .. math::\n",
      "    \n",
      "       out[n,i,:,:] = bias[i] + \\sum_{j=0}^{channel} data[n,j,:,:] \\star\n",
      "       weight[i,j,:,:]\n",
      "    \n",
      "    where :math:`\\star` is the 2-D cross-correlation operator.\n",
      "    \n",
      "    For general 2-D convolution, the shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_height, out_width)*.\n",
      "    \n",
      "    Define::\n",
      "    \n",
      "      f(x,k,p,s,d) = floor((x+2*p-d*(k-1)-1)/s)+1\n",
      "    \n",
      "    then we have::\n",
      "    \n",
      "      out_height=f(height, kernel[0], pad[0], stride[0], dilate[0])\n",
      "      out_width=f(width, kernel[1], pad[1], stride[1], dilate[1])\n",
      "    \n",
      "    If ``no_bias`` is set to be true, then the ``bias`` term is ignored.\n",
      "    \n",
      "    The default data ``layout`` is *NCHW*, namely *(batch_size, channel, height,\n",
      "    width)*. We can choose other layouts such as *NWC*.\n",
      "    \n",
      "    If ``num_group`` is larger than 1, denoted by *g*, then split the input ``data``\n",
      "    evenly into *g* parts along the channel axis, and also evenly split ``weight``\n",
      "    along the first dimension. Next compute the convolution on the *i*-th part of\n",
      "    the data with the *i*-th weight part. The output is obtained by concatenating all\n",
      "    the *g* results.\n",
      "    \n",
      "    1-D convolution does not have *height* dimension but only *width* in space.\n",
      "    \n",
      "    - **data**: *(batch_size, channel, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_width)*.\n",
      "    \n",
      "    3-D convolution adds an additional *depth* dimension besides *height* and\n",
      "    *width*. The shapes are\n",
      "    \n",
      "    - **data**: *(batch_size, channel, depth, height, width)*\n",
      "    - **weight**: *(num_filter, channel, kernel[0], kernel[1], kernel[2])*\n",
      "    - **bias**: *(num_filter,)*\n",
      "    - **out**: *(batch_size, num_filter, out_depth, out_height, out_width)*.\n",
      "    \n",
      "    Both ``weight`` and ``bias`` are learnable parameters.\n",
      "    \n",
      "    There are other options to tune the performance.\n",
      "    \n",
      "    - **cudnn_tune**: enable this option leads to higher startup time but may give\n",
      "      faster speed. Options are\n",
      "    \n",
      "      - **off**: no tuning\n",
      "      - **limited_workspace**:run test and pick the fastest algorithm that doesn't\n",
      "        exceed workspace limit.\n",
      "      - **fastest**: pick the fastest algorithm and ignore workspace limit.\n",
      "      - **None** (default): the behavior is determined by environment variable\n",
      "        ``MXNET_CUDNN_AUTOTUNE_DEFAULT``. 0 for off, 1 for limited workspace\n",
      "        (default), 2 for fastest.\n",
      "    \n",
      "    - **workspace**: A large number leads to more (GPU) memory usage but may improve\n",
      "      the performance.\n",
      "    \n",
      "    \n",
      "    \n",
      "    Defined in src/operator/nn/convolution.cc:L472\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : NDArray\n",
      "        Input data to the ConvolutionOp.\n",
      "    weight : NDArray\n",
      "        Weight matrix.\n",
      "    bias : NDArray\n",
      "        Bias parameter.\n",
      "    kernel : Shape(tuple), required\n",
      "        Convolution kernel size: (w,), (h, w) or (d, h, w)\n",
      "    stride : Shape(tuple), optional, default=[]\n",
      "        Convolution stride: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.\n",
      "    dilate : Shape(tuple), optional, default=[]\n",
      "        Convolution dilate: (w,), (h, w) or (d, h, w). Defaults to 1 for each dimension.\n",
      "    pad : Shape(tuple), optional, default=[]\n",
      "        Zero pad for convolution: (w,), (h, w) or (d, h, w). Defaults to no padding.\n",
      "    num_filter : int (non-negative), required\n",
      "        Convolution filter(channel) number\n",
      "    num_group : int (non-negative), optional, default=1\n",
      "        Number of group partitions.\n",
      "    workspace : long (non-negative), optional, default=1024\n",
      "        Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used, it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the maximum temporary storage used for tuning the best CUDNN kernel when `limited_workspace` strategy is used.\n",
      "    no_bias : boolean, optional, default=0\n",
      "        Whether to disable bias parameter.\n",
      "    cudnn_tune : {None, 'fastest', 'limited_workspace', 'off'},optional, default='None'\n",
      "        Whether to pick convolution algo by running performance test.\n",
      "    cudnn_off : boolean, optional, default=0\n",
      "        Turn off cudnn for this layer.\n",
      "    layout : {None, 'NCDHW', 'NCHW', 'NCW', 'NDHWC', 'NHWC'},optional, default='None'\n",
      "        Set layout for input, output and weight. Empty for\n",
      "        default layout: NCW for 1d, NCHW for 2d and NCDHW for 3d.NHWC and NDHWC are only supported on GPU.\n",
      "    \n",
      "    out : NDArray, optional\n",
      "        The output NDArray to hold the result.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : NDArray or list of NDArrays\n",
      "        The output of this function.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mx.ndarray.Convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
